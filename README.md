# HW1_Regression_with_inference_base
В ходе выполнения данного домашнего задания я провела следующие шаги:
1. Сначала провела исследовательский анализ данных по датасету на автомобили - посмотрела содержание датасета, проверила его качество. Потом провела очистку и предобработку данных для возможности обучения моделей - удалила дубликаты, выбрала подходящие столбцы с данными. Еще посмотрела статистики по содержанию датасета. Сделала визуализации датасета, особенно в плане наглядности помогло создание тепловой карты - в ней наглядно и понятно можно увидеть связи между переменными.
2. После разделения датасета на трейн и тестовую часть провела обучение модели простой линейной регрессии (MSE (Test):  233691781105.6572, R2  (Test):  0.5935) Такой странный показатель средне-квадратичной ошибки говорит о том, что у нас есть проблемы с данными в датасете, хотя коэффициент детерминации лежит в нормальном диапазоне. Потом обучила модель линейной регрессии на стандартизированных данных. Но стандартизация данных не помогла в улучшении модели - метрики MSE, R^2 не изменились. Потом определила наиболее информативные признаки. Наиболее информативным признаком в предсказании цены оказался max_power (максимальная мощность).
3. Потом провела обучение модели LASSO регрессии. Метрики качества не изменились (MSE (Test Lasso):  233692451723.1874, R2  (Test Lasso):  0.5935)
4. Затем перебором по сетке (c 10-ю фолдами) подбирала оптимальные параметры для Lasso-регрессии с помощью грид-сёрча. Метрики MSE (Test Best Lasso): 233758808297.8584б и R2  (Test Best Lasso): 0.5933 немного изменились. R^2 чуть-чуть уменьшилась, но это не критично.
5. Далее перебором по сетке (c 10-ю фолдами) подбирала оптимальные параметры для ElasticNet регрессии с помощью грид-сёрча. Лучший MSE (умноженный на -1) получился: 119139666091.2984. Немного лучше чем в предыдущих расчетах. Увеличила гиперпараметр max_iter до 10 000, но модель все равно не сошлась.
6. Далее закодировала категориальные фичи методом OneHot-кодирования.
7. Затем провела обучение гребневой (Ridge) регрессии. Получила лучший R^2 на кросс-валидации: 0.5881, что по факту не сильно отличается от значений R^2 при линейной и ЛАССО регрессии.
8. В данном ноутбуке мне не удалось решить проблему со странным значением MSE, пробовала вариант с добавлением столбца "torque", но это тоже не сильно помогло. По моему предположению необходимо провести более тщательный анализ датасета и выбор фичей для обучения моделей регрессии.
